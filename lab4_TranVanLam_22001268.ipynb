{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a29e7b5dfb154512aea2e6221f540e9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6d8509ac39f48428e7a2e234d16df4f",
              "IPY_MODEL_92d70482f37a4c8ba6826fa6a151c781",
              "IPY_MODEL_6f78d3ca143f47a3b0e4019603415254"
            ],
            "layout": "IPY_MODEL_12549566e775440781fb0312d07ac214"
          }
        },
        "c6d8509ac39f48428e7a2e234d16df4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e631751fd747ebbd9805434d4e3393",
            "placeholder": "​",
            "style": "IPY_MODEL_67549325418946ff8f897e99a6799f23",
            "value": "README.md: "
          }
        },
        "92d70482f37a4c8ba6826fa6a151c781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_047dd576bc524c898b5e3f60e4b237d4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2488237b407540bbb20a8a05dbefa59f",
            "value": 1
          }
        },
        "6f78d3ca143f47a3b0e4019603415254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f96a03fd1a54257bef18ed65ce9d59b",
            "placeholder": "​",
            "style": "IPY_MODEL_27780d6d4e1e42e29b342c81f5a5d798",
            "value": " 1.39k/? [00:00&lt;00:00, 28.4kB/s]"
          }
        },
        "12549566e775440781fb0312d07ac214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e631751fd747ebbd9805434d4e3393": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67549325418946ff8f897e99a6799f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "047dd576bc524c898b5e3f60e4b237d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "2488237b407540bbb20a8a05dbefa59f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f96a03fd1a54257bef18ed65ce9d59b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27780d6d4e1e42e29b342c81f5a5d798": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0158dc06a1974efba748b871714933a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_236a1effcb5b486697f314f490c6bc97",
              "IPY_MODEL_d6cc3067282a437bb9b8e3d7c3161263",
              "IPY_MODEL_39baa7631a6d41dd8de7b430f5fbf6ca"
            ],
            "layout": "IPY_MODEL_afa69b12f2104dfa9b648266240ea625"
          }
        },
        "236a1effcb5b486697f314f490c6bc97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3a2de7756c04555a42d99e804e888d7",
            "placeholder": "​",
            "style": "IPY_MODEL_b24545d831ac4dad92cb27af9f598538",
            "value": "sent_train.csv: "
          }
        },
        "d6cc3067282a437bb9b8e3d7c3161263": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e84cb5f601cd4daf90650fd8fd59026b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cc79a35c394546ba97e12040b0ec6919",
            "value": 1
          }
        },
        "39baa7631a6d41dd8de7b430f5fbf6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d0dd708cd3d44429957b5dc23d43cf1",
            "placeholder": "​",
            "style": "IPY_MODEL_4740ce7371fa492690e1edd2417d554d",
            "value": " 859k/? [00:00&lt;00:00, 18.2MB/s]"
          }
        },
        "afa69b12f2104dfa9b648266240ea625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3a2de7756c04555a42d99e804e888d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b24545d831ac4dad92cb27af9f598538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e84cb5f601cd4daf90650fd8fd59026b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "cc79a35c394546ba97e12040b0ec6919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d0dd708cd3d44429957b5dc23d43cf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4740ce7371fa492690e1edd2417d554d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76de77c887de4b2a99282e65e3fbca7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f20c8b54e6a643a19b3694603c68e61e",
              "IPY_MODEL_061e1e32657746d28d6551d295f4dd2a",
              "IPY_MODEL_26e1d201c9ca424a8acb650eaab69d57"
            ],
            "layout": "IPY_MODEL_97c7728602494343a63589368ab34f9b"
          }
        },
        "f20c8b54e6a643a19b3694603c68e61e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb7317d4c1364c61a8ea9f95b5887427",
            "placeholder": "​",
            "style": "IPY_MODEL_50901571774048d79381c116cf8ea31e",
            "value": "sent_valid.csv: "
          }
        },
        "061e1e32657746d28d6551d295f4dd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a251693c0d240ff94ee0d61c66a3cd7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_253bc3c26ad047818caf57f8b4b28c79",
            "value": 1
          }
        },
        "26e1d201c9ca424a8acb650eaab69d57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44bd2413ce6d4aa0a7793a739b830526",
            "placeholder": "​",
            "style": "IPY_MODEL_47a2a650bac9484a80e3a508edc6b311",
            "value": " 217k/? [00:00&lt;00:00, 13.1MB/s]"
          }
        },
        "97c7728602494343a63589368ab34f9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb7317d4c1364c61a8ea9f95b5887427": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50901571774048d79381c116cf8ea31e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2a251693c0d240ff94ee0d61c66a3cd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "253bc3c26ad047818caf57f8b4b28c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "44bd2413ce6d4aa0a7793a739b830526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a2a650bac9484a80e3a508edc6b311": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e296bb30098e4870b61ee4728c6c1f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dbeb00080874226b29e469f1fa31135",
              "IPY_MODEL_0ffdcc41ea3e408bbf53be02a95d5a09",
              "IPY_MODEL_18efe33e365a43e48e13258ef5a817c0"
            ],
            "layout": "IPY_MODEL_fbced6aeab85497c89329534b7a655ae"
          }
        },
        "7dbeb00080874226b29e469f1fa31135": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a19ca815fa84451be477692d7c9fb16",
            "placeholder": "​",
            "style": "IPY_MODEL_5c4b2c2148af44da8f92d59d6671c8c6",
            "value": "Generating train split: 100%"
          }
        },
        "0ffdcc41ea3e408bbf53be02a95d5a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea80b51650c477cb5df46f84a1f226e",
            "max": 9543,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3904a968bdc445eeb01a62e33c3ad867",
            "value": 9543
          }
        },
        "18efe33e365a43e48e13258ef5a817c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3f022c0caac4d388c12b89f23a020f7",
            "placeholder": "​",
            "style": "IPY_MODEL_8edf859155204823a647020775199448",
            "value": " 9543/9543 [00:00&lt;00:00, 101850.80 examples/s]"
          }
        },
        "fbced6aeab85497c89329534b7a655ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a19ca815fa84451be477692d7c9fb16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c4b2c2148af44da8f92d59d6671c8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ea80b51650c477cb5df46f84a1f226e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3904a968bdc445eeb01a62e33c3ad867": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3f022c0caac4d388c12b89f23a020f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8edf859155204823a647020775199448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e86ee7c89bfd4e3da3a29c935ad5da37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8eadded6ff8b440ebd394dbc7cf406da",
              "IPY_MODEL_a22290c87e184ba580f76851f48a92f7",
              "IPY_MODEL_fda7d0fabc914c838d8f6016211d605b"
            ],
            "layout": "IPY_MODEL_3cf1edf6bec0463abdc51e1aacad2643"
          }
        },
        "8eadded6ff8b440ebd394dbc7cf406da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0c158f099984b1696c69ba67b37b945",
            "placeholder": "​",
            "style": "IPY_MODEL_e313a1683d2b4c27a70940263cfc9f58",
            "value": "Generating validation split: 100%"
          }
        },
        "a22290c87e184ba580f76851f48a92f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d52a3e33413444628aed35f1e37c4414",
            "max": 2388,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84e339b856a54fdd918b29c639804f1e",
            "value": 2388
          }
        },
        "fda7d0fabc914c838d8f6016211d605b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36596373d40b4f19b30eb9e2def0f194",
            "placeholder": "​",
            "style": "IPY_MODEL_438d7246f85e4f6d955d7e45261cbc95",
            "value": " 2388/2388 [00:00&lt;00:00, 60927.90 examples/s]"
          }
        },
        "3cf1edf6bec0463abdc51e1aacad2643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0c158f099984b1696c69ba67b37b945": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e313a1683d2b4c27a70940263cfc9f58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d52a3e33413444628aed35f1e37c4414": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e339b856a54fdd918b29c639804f1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "36596373d40b4f19b30eb9e2def0f194": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438d7246f85e4f6d955d7e45261cbc95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281,
          "referenced_widgets": [
            "a29e7b5dfb154512aea2e6221f540e9d",
            "c6d8509ac39f48428e7a2e234d16df4f",
            "92d70482f37a4c8ba6826fa6a151c781",
            "6f78d3ca143f47a3b0e4019603415254",
            "12549566e775440781fb0312d07ac214",
            "84e631751fd747ebbd9805434d4e3393",
            "67549325418946ff8f897e99a6799f23",
            "047dd576bc524c898b5e3f60e4b237d4",
            "2488237b407540bbb20a8a05dbefa59f",
            "5f96a03fd1a54257bef18ed65ce9d59b",
            "27780d6d4e1e42e29b342c81f5a5d798",
            "0158dc06a1974efba748b871714933a9",
            "236a1effcb5b486697f314f490c6bc97",
            "d6cc3067282a437bb9b8e3d7c3161263",
            "39baa7631a6d41dd8de7b430f5fbf6ca",
            "afa69b12f2104dfa9b648266240ea625",
            "e3a2de7756c04555a42d99e804e888d7",
            "b24545d831ac4dad92cb27af9f598538",
            "e84cb5f601cd4daf90650fd8fd59026b",
            "cc79a35c394546ba97e12040b0ec6919",
            "8d0dd708cd3d44429957b5dc23d43cf1",
            "4740ce7371fa492690e1edd2417d554d",
            "76de77c887de4b2a99282e65e3fbca7b",
            "f20c8b54e6a643a19b3694603c68e61e",
            "061e1e32657746d28d6551d295f4dd2a",
            "26e1d201c9ca424a8acb650eaab69d57",
            "97c7728602494343a63589368ab34f9b",
            "cb7317d4c1364c61a8ea9f95b5887427",
            "50901571774048d79381c116cf8ea31e",
            "2a251693c0d240ff94ee0d61c66a3cd7",
            "253bc3c26ad047818caf57f8b4b28c79",
            "44bd2413ce6d4aa0a7793a739b830526",
            "47a2a650bac9484a80e3a508edc6b311",
            "e296bb30098e4870b61ee4728c6c1f07",
            "7dbeb00080874226b29e469f1fa31135",
            "0ffdcc41ea3e408bbf53be02a95d5a09",
            "18efe33e365a43e48e13258ef5a817c0",
            "fbced6aeab85497c89329534b7a655ae",
            "7a19ca815fa84451be477692d7c9fb16",
            "5c4b2c2148af44da8f92d59d6671c8c6",
            "4ea80b51650c477cb5df46f84a1f226e",
            "3904a968bdc445eeb01a62e33c3ad867",
            "b3f022c0caac4d388c12b89f23a020f7",
            "8edf859155204823a647020775199448",
            "e86ee7c89bfd4e3da3a29c935ad5da37",
            "8eadded6ff8b440ebd394dbc7cf406da",
            "a22290c87e184ba580f76851f48a92f7",
            "fda7d0fabc914c838d8f6016211d605b",
            "3cf1edf6bec0463abdc51e1aacad2643",
            "d0c158f099984b1696c69ba67b37b945",
            "e313a1683d2b4c27a70940263cfc9f58",
            "d52a3e33413444628aed35f1e37c4414",
            "84e339b856a54fdd918b29c639804f1e",
            "36596373d40b4f19b30eb9e2def0f194",
            "438d7246f85e4f6d955d7e45261cbc95"
          ]
        },
        "id": "Y3ZOMhlgy0Rn",
        "outputId": "c50ca70d-2efe-4f20-9652-18337eb9b45f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a29e7b5dfb154512aea2e6221f540e9d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sent_train.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0158dc06a1974efba748b871714933a9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sent_valid.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "76de77c887de4b2a99282e65e3fbca7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9543 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e296bb30098e4870b61ee4728c6c1f07"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/2388 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e86ee7c89bfd4e3da3a29c935ad5da37"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"zeroshot/twitter-financial-news-sentiment\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List, Dict\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TextClassifier:\n",
        "    \"\"\"\n",
        "    A text classification model using Logistic Regression.\n",
        "\n",
        "    This class wraps a vectorizer and a logistic regression model to perform\n",
        "    text classification tasks such as sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vectorizer):\n",
        "        \"\"\"\n",
        "        Initialize the TextClassifier.\n",
        "\n",
        "        Args:\n",
        "            vectorizer: A vectorizer instance (e.g., TfidfVectorizer, CountVectorizer)\n",
        "                       that transforms text into numerical features.\n",
        "        \"\"\"\n",
        "        self.vectorizer = vectorizer\n",
        "        self._model = None\n",
        "\n",
        "    def fit(self, texts: List[str], labels: List[int]):\n",
        "        \"\"\"\n",
        "        Train the text classifier on the given texts and labels.\n",
        "\n",
        "        Args:\n",
        "            texts: List of text documents to train on\n",
        "            labels: List of corresponding labels (e.g., 0 for negative, 1 for positive)\n",
        "\n",
        "        Returns:\n",
        "            self: Returns the instance itself for method chaining\n",
        "        \"\"\"\n",
        "        # Transform texts into feature matrix using the vectorizer\n",
        "        X = self.vectorizer.fit_transform(texts)\n",
        "\n",
        "        # Initialize and train the Logistic Regression model\n",
        "        self._model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "        self._model.fit(X, labels)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predict labels for new texts.\n",
        "\n",
        "        Args:\n",
        "            texts: List of text documents to predict labels for\n",
        "\n",
        "        Returns:\n",
        "            List of predicted labels\n",
        "\n",
        "        Raises:\n",
        "            ValueError: If the model has not been trained yet\n",
        "        \"\"\"\n",
        "        if self._model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Please call fit() first.\")\n",
        "\n",
        "        # Transform texts using the already fitted vectorizer\n",
        "        X = self.vectorizer.transform(texts)\n",
        "\n",
        "        # Predict labels\n",
        "        predictions = self._model.predict(X)\n",
        "\n",
        "        return predictions.tolist()\n",
        "\n",
        "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate the model's predictions using various metrics.\n",
        "\n",
        "        Args:\n",
        "            y_true: List of true labels\n",
        "            y_pred: List of predicted labels\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing accuracy, precision, recall, and f1_score\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "\n",
        "        return metrics\n",
        "\n",
        "\n",
        "# Example usage and testing\n",
        "if __name__ == \"__main__\":\n",
        "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "    # Task 1: Data Preparation\n",
        "    texts = [\n",
        "        \"This movie is fantastic and I love it!\",\n",
        "        \"I hate this film, it's terrible.\",\n",
        "        \"The acting was superb, a truly great experience.\",\n",
        "        \"What a waste of time, absolutely boring.\",\n",
        "        \"Highly recommend this, a masterpiece.\",\n",
        "        \"Could not finish watching, so bad.\"\n",
        "    ]\n",
        "    labels = [1, 0, 1, 0, 1, 0]  # 1 for positive, 0 for negative\n",
        "\n",
        "    # Initialize vectorizer\n",
        "    vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
        "\n",
        "    # Task 2: TextClassifier Implementation\n",
        "    # Create and train the classifier\n",
        "    classifier = TextClassifier(vectorizer)\n",
        "    classifier.fit(texts, labels)\n",
        "\n",
        "    # Make predictions on the training data\n",
        "    predictions = classifier.predict(texts)\n",
        "\n",
        "    # Evaluate the model\n",
        "    metrics = classifier.evaluate(labels, predictions)\n",
        "\n",
        "    # Print results\n",
        "    print(\"Training Data Predictions:\")\n",
        "    for text, true_label, pred_label in zip(texts, labels, predictions):\n",
        "        sentiment = \"Positive\" if pred_label == 1 else \"Negative\"\n",
        "        correct = \"✓\" if true_label == pred_label else \"✗\"\n",
        "        print(f\"{correct} [{sentiment}] {text}\")\n",
        "\n",
        "    print(\"\\nEvaluation Metrics:\")\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        print(f\"{metric_name.capitalize()}: {metric_value:.4f}\")\n",
        "\n",
        "    # Test on new data\n",
        "    print(\"\\nTesting on new data:\")\n",
        "    test_texts = [\n",
        "        \"This is an amazing film, loved every minute!\",\n",
        "        \"Terrible movie, don't waste your money.\",\n",
        "        \"Outstanding performance by the actors.\"\n",
        "    ]\n",
        "\n",
        "    test_predictions = classifier.predict(test_texts)\n",
        "    for text, pred in zip(test_texts, test_predictions):\n",
        "        sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "        print(f\"[{sentiment}] {text}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccn23Ojz1t05",
        "outputId": "787d5dd1-8bd0-4443-9cbc-78b0405d59ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Data Predictions:\n",
            "✓ [Positive] This movie is fantastic and I love it!\n",
            "✓ [Negative] I hate this film, it's terrible.\n",
            "✓ [Positive] The acting was superb, a truly great experience.\n",
            "✓ [Negative] What a waste of time, absolutely boring.\n",
            "✓ [Positive] Highly recommend this, a masterpiece.\n",
            "✓ [Negative] Could not finish watching, so bad.\n",
            "\n",
            "Evaluation Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1_score: 1.0000\n",
            "\n",
            "Testing on new data:\n",
            "[Negative] This is an amazing film, loved every minute!\n",
            "[Negative] Terrible movie, don't waste your money.\n",
            "[Negative] Outstanding performance by the actors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lab 5 Test: Text Classification with Train/Test Split\n",
        "This file tests the TextClassifier implementation with proper data splitting.\n",
        "\"\"\"\n",
        "\n",
        "from typing import List\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import re\n",
        "\n",
        "\n",
        "# RegexTokenizer implementation (from previous labs)\n",
        "class RegexTokenizer:\n",
        "    \"\"\"\n",
        "    A simple tokenizer that uses regular expressions to split text into tokens.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, pattern: str = r'\\b\\w+\\b'):\n",
        "        \"\"\"\n",
        "        Initialize the tokenizer with a regex pattern.\n",
        "\n",
        "        Args:\n",
        "            pattern: Regular expression pattern for tokenization\n",
        "        \"\"\"\n",
        "        self.pattern = pattern\n",
        "\n",
        "    def tokenize(self, text: str) -> List[str]:\n",
        "        \"\"\"\n",
        "        Tokenize the input text using the regex pattern.\n",
        "\n",
        "        Args:\n",
        "            text: Input text to tokenize\n",
        "\n",
        "        Returns:\n",
        "            List of tokens\n",
        "        \"\"\"\n",
        "        text = text.lower()\n",
        "        tokens = re.findall(self.pattern, text)\n",
        "        return tokens\n",
        "\n",
        "\n",
        "# TextClassifier implementation (from Task 2)\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from typing import Dict\n",
        "\n",
        "\n",
        "class TextClassifier:\n",
        "    \"\"\"\n",
        "    A text classification model using Logistic Regression.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vectorizer):\n",
        "        \"\"\"\n",
        "        Initialize the TextClassifier.\n",
        "\n",
        "        Args:\n",
        "            vectorizer: A vectorizer instance\n",
        "        \"\"\"\n",
        "        self.vectorizer = vectorizer\n",
        "        self._model = None\n",
        "\n",
        "    def fit(self, texts: List[str], labels: List[int]):\n",
        "        \"\"\"\n",
        "        Train the text classifier.\n",
        "\n",
        "        Args:\n",
        "            texts: List of text documents\n",
        "            labels: List of corresponding labels\n",
        "        \"\"\"\n",
        "        X = self.vectorizer.fit_transform(texts)\n",
        "        self._model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "        self._model.fit(X, labels)\n",
        "        return self\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[int]:\n",
        "        \"\"\"\n",
        "        Predict labels for new texts.\n",
        "\n",
        "        Args:\n",
        "            texts: List of text documents\n",
        "\n",
        "        Returns:\n",
        "            List of predicted labels\n",
        "        \"\"\"\n",
        "        if self._model is None:\n",
        "            raise ValueError(\"Model has not been trained yet. Please call fit() first.\")\n",
        "\n",
        "        X = self.vectorizer.transform(texts)\n",
        "        predictions = self._model.predict(X)\n",
        "        return predictions.tolist()\n",
        "\n",
        "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate the model's predictions.\n",
        "\n",
        "        Args:\n",
        "            y_true: List of true labels\n",
        "            y_pred: List of predicted labels\n",
        "\n",
        "        Returns:\n",
        "            Dictionary containing metrics\n",
        "        \"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to test the TextClassifier with train/test split.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 70)\n",
        "    print(\"LAB 5 TEST: TEXT CLASSIFICATION WITH TRAIN/TEST SPLIT\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    # Task 3: Define the dataset\n",
        "    texts = [\n",
        "        \"This movie is fantastic and I love it!\",\n",
        "        \"I hate this film, it's terrible.\",\n",
        "        \"The acting was superb, a truly great experience.\",\n",
        "        \"What a waste of time, absolutely boring.\",\n",
        "        \"Highly recommend this, a masterpiece.\",\n",
        "        \"Could not finish watching, so bad.\",\n",
        "        \"Amazing storyline, kept me engaged throughout.\",\n",
        "        \"Disappointing and poorly executed.\",\n",
        "        \"Brilliant cinematography and great performances.\",\n",
        "        \"Not worth watching, very dull.\",\n",
        "        \"Exceptional movie, one of the best I've seen.\",\n",
        "        \"Awful, I regret watching this.\",\n",
        "        \"Wonderful experience, loved every scene.\",\n",
        "        \"Boring and predictable plot.\",\n",
        "        \"Outstanding film with excellent direction.\",\n",
        "        \"Terrible waste of money and time.\",\n",
        "        \"Incredible acting and beautiful visuals.\",\n",
        "        \"So bad, couldn't watch till the end.\",\n",
        "        \"Superb entertainment, highly enjoyable.\",\n",
        "        \"Worst movie ever, absolutely horrible.\"\n",
        "    ]\n",
        "\n",
        "    labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
        "    # 1 for positive, 0 for negative\n",
        "\n",
        "    print(f\"\\nTotal dataset size: {len(texts)} samples\")\n",
        "    print(f\"Positive samples: {sum(labels)}\")\n",
        "    print(f\"Negative samples: {len(labels) - sum(labels)}\")\n",
        "\n",
        "    # Split data into training and testing sets (80% train, 20% test)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        texts,\n",
        "        labels,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=labels  # Maintain class distribution\n",
        "    )\n",
        "\n",
        "    print(f\"\\nTraining set size: {len(X_train)} samples\")\n",
        "    print(f\"Testing set size: {len(X_test)} samples\")\n",
        "\n",
        "    # Instantiate RegexTokenizer\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 1: Initialize RegexTokenizer\")\n",
        "    print(\"-\" * 70)\n",
        "    tokenizer = RegexTokenizer(pattern=r'\\b\\w+\\b')\n",
        "    print(\"✓ RegexTokenizer initialized\")\n",
        "\n",
        "    # Example tokenization\n",
        "    example_text = X_train[0]\n",
        "    tokens = tokenizer.tokenize(example_text)\n",
        "    print(f\"\\nExample tokenization:\")\n",
        "    print(f\"Text: '{example_text}'\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    # Instantiate TfidfVectorizer\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 2: Initialize TfidfVectorizer\")\n",
        "    print(\"-\" * 70)\n",
        "    vectorizer = TfidfVectorizer(\n",
        "        max_features=100,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 2),  # Use unigrams and bigrams\n",
        "        min_df=1\n",
        "    )\n",
        "    print(\"✓ TfidfVectorizer initialized\")\n",
        "    print(f\"  - max_features: 100\")\n",
        "    print(f\"  - stop_words: 'english'\")\n",
        "    print(f\"  - ngram_range: (1, 2)\")\n",
        "\n",
        "    # Instantiate TextClassifier\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 3: Initialize TextClassifier\")\n",
        "    print(\"-\" * 70)\n",
        "    classifier = TextClassifier(vectorizer)\n",
        "    print(\"✓ TextClassifier initialized with TfidfVectorizer\")\n",
        "\n",
        "    # Train the classifier\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 4: Train the Classifier\")\n",
        "    print(\"-\" * 70)\n",
        "    print(\"Training in progress...\")\n",
        "    classifier.fit(X_train, y_train)\n",
        "    print(\"✓ Classifier trained successfully\")\n",
        "\n",
        "    # Make predictions on training data\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 5: Evaluate on Training Data\")\n",
        "    print(\"-\" * 70)\n",
        "    train_predictions = classifier.predict(X_train)\n",
        "    train_metrics = classifier.evaluate(y_train, train_predictions)\n",
        "\n",
        "    print(\"\\nTraining Set Metrics:\")\n",
        "    for metric_name, metric_value in train_metrics.items():\n",
        "        print(f\"  {metric_name.capitalize():12s}: {metric_value:.4f}\")\n",
        "\n",
        "    # Make predictions on test data\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Step 6: Evaluate on Test Data\")\n",
        "    print(\"-\" * 70)\n",
        "    test_predictions = classifier.predict(X_test)\n",
        "    test_metrics = classifier.evaluate(y_test, test_predictions)\n",
        "\n",
        "    print(\"\\nTest Set Metrics:\")\n",
        "    for metric_name, metric_value in test_metrics.items():\n",
        "        print(f\"  {metric_name.capitalize():12s}: {metric_value:.4f}\")\n",
        "\n",
        "    # Display test predictions\n",
        "    print(\"\\n\" + \"-\" * 70)\n",
        "    print(\"Test Set Predictions Details:\")\n",
        "    print(\"-\" * 70)\n",
        "    for i, (text, true_label, pred_label) in enumerate(zip(X_test, y_test, test_predictions), 1):\n",
        "        sentiment_true = \"Positive\" if true_label == 1 else \"Negative\"\n",
        "        sentiment_pred = \"Positive\" if pred_label == 1 else \"Negative\"\n",
        "        correct = \"✓\" if true_label == pred_label else \"✗\"\n",
        "        print(f\"\\n{i}. {correct} Text: '{text}'\")\n",
        "        print(f\"   True: {sentiment_true} | Predicted: {sentiment_pred}\")\n",
        "\n",
        "    # Test on new unseen data\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"BONUS: Testing on New Unseen Data\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "    new_texts = [\n",
        "        \"This is an amazing film, loved every minute!\",\n",
        "        \"Terrible movie, don't waste your money.\",\n",
        "        \"Outstanding performance by the actors.\",\n",
        "        \"Very disappointing, expected much better.\",\n",
        "        \"Absolute masterpiece, beautifully crafted.\"\n",
        "    ]\n",
        "\n",
        "    new_predictions = classifier.predict(new_texts)\n",
        "\n",
        "    for i, (text, pred) in enumerate(zip(new_texts, new_predictions), 1):\n",
        "        sentiment = \"Positive\" if pred == 1 else \"Negative\"\n",
        "        emoji = \"😊\" if pred == 1 else \"😞\"\n",
        "        print(f\"\\n{i}. [{sentiment} {emoji}] {text}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"TEST COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OPSEPY6p14t5",
        "outputId": "fc67747f-268a-4942-e28e-fbd872860c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "LAB 5 TEST: TEXT CLASSIFICATION WITH TRAIN/TEST SPLIT\n",
            "======================================================================\n",
            "\n",
            "Total dataset size: 20 samples\n",
            "Positive samples: 10\n",
            "Negative samples: 10\n",
            "\n",
            "Training set size: 16 samples\n",
            "Testing set size: 4 samples\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 1: Initialize RegexTokenizer\n",
            "----------------------------------------------------------------------\n",
            "✓ RegexTokenizer initialized\n",
            "\n",
            "Example tokenization:\n",
            "Text: 'Worst movie ever, absolutely horrible.'\n",
            "Tokens: ['worst', 'movie', 'ever', 'absolutely', 'horrible']\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 2: Initialize TfidfVectorizer\n",
            "----------------------------------------------------------------------\n",
            "✓ TfidfVectorizer initialized\n",
            "  - max_features: 100\n",
            "  - stop_words: 'english'\n",
            "  - ngram_range: (1, 2)\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 3: Initialize TextClassifier\n",
            "----------------------------------------------------------------------\n",
            "✓ TextClassifier initialized with TfidfVectorizer\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 4: Train the Classifier\n",
            "----------------------------------------------------------------------\n",
            "Training in progress...\n",
            "✓ Classifier trained successfully\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 5: Evaluate on Training Data\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Training Set Metrics:\n",
            "  Accuracy    : 1.0000\n",
            "  Precision   : 1.0000\n",
            "  Recall      : 1.0000\n",
            "  F1_score    : 1.0000\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Step 6: Evaluate on Test Data\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "Test Set Metrics:\n",
            "  Accuracy    : 0.7500\n",
            "  Precision   : 0.6667\n",
            "  Recall      : 1.0000\n",
            "  F1_score    : 0.8000\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Test Set Predictions Details:\n",
            "----------------------------------------------------------------------\n",
            "\n",
            "1. ✓ Text: 'Boring and predictable plot.'\n",
            "   True: Negative | Predicted: Negative\n",
            "\n",
            "2. ✗ Text: 'Disappointing and poorly executed.'\n",
            "   True: Negative | Predicted: Positive\n",
            "\n",
            "3. ✓ Text: 'Highly recommend this, a masterpiece.'\n",
            "   True: Positive | Predicted: Positive\n",
            "\n",
            "4. ✓ Text: 'Wonderful experience, loved every scene.'\n",
            "   True: Positive | Predicted: Positive\n",
            "\n",
            "======================================================================\n",
            "BONUS: Testing on New Unseen Data\n",
            "======================================================================\n",
            "\n",
            "1. [Positive 😊] This is an amazing film, loved every minute!\n",
            "\n",
            "2. [Negative 😞] Terrible movie, don't waste your money.\n",
            "\n",
            "3. [Positive 😊] Outstanding performance by the actors.\n",
            "\n",
            "4. [Positive 😊] Very disappointing, expected much better.\n",
            "\n",
            "5. [Positive 😊] Absolute masterpiece, beautifully crafted.\n",
            "\n",
            "======================================================================\n",
            "TEST COMPLETED SUCCESSFULLY!\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cài đặt Java\n",
        "!apt-get update\n",
        "!apt-get install -y openjdk-8-jdk-headless\n",
        "\n",
        "# Set JAVA_HOME\n",
        "import os\n",
        "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "\n",
        "# Verify Java installation\n",
        "!java -version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O71eTLjG23PS",
        "outputId": "d03287e6-da03-449b-90cc-a5b6cdce2167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connecting to security.\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:4 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.2 kB]\n",
            "Hit:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,411 kB]\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,822 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,520 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,161 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [5,963 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,594 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,855 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,289 kB]\n",
            "Fetched 35.1 MB in 35s (1,014 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 libxtst6\n",
            "  openjdk-8-jre-headless\n",
            "Suggested packages:\n",
            "  default-jre pcscd openjdk-8-demo openjdk-8-source libnss-mdns\n",
            "  fonts-dejavu-extra fonts-nanum fonts-ipafont-gothic fonts-ipafont-mincho\n",
            "  fonts-wqy-microhei fonts-wqy-zenhei fonts-indic\n",
            "The following NEW packages will be installed:\n",
            "  ca-certificates-java java-common libpcsclite1 libxtst6\n",
            "  openjdk-8-jdk-headless openjdk-8-jre-headless\n",
            "0 upgraded, 6 newly installed, 0 to remove and 47 not upgraded.\n",
            "Need to get 39.7 MB of archives.\n",
            "After this operation, 144 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 java-common all 0.72build2 [6,782 B]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpcsclite1 amd64 1.9.5-3ubuntu1 [19.8 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jre-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [30.8 MB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ca-certificates-java all 20190909ubuntu1.2 [12.1 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 openjdk-8-jdk-headless amd64 8u462-ga~us1-0ubuntu2~22.04.2 [8,849 kB]\n",
            "Fetched 39.7 MB in 6s (6,671 kB/s)\n",
            "Selecting previously unselected package java-common.\n",
            "(Reading database ... 125080 files and directories currently installed.)\n",
            "Preparing to unpack .../0-java-common_0.72build2_all.deb ...\n",
            "Unpacking java-common (0.72build2) ...\n",
            "Selecting previously unselected package libpcsclite1:amd64.\n",
            "Preparing to unpack .../1-libpcsclite1_1.9.5-3ubuntu1_amd64.deb ...\n",
            "Unpacking libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../2-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package openjdk-8-jre-headless:amd64.\n",
            "Preparing to unpack .../3-openjdk-8-jre-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Selecting previously unselected package ca-certificates-java.\n",
            "Preparing to unpack .../4-ca-certificates-java_20190909ubuntu1.2_all.deb ...\n",
            "Unpacking ca-certificates-java (20190909ubuntu1.2) ...\n",
            "Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n",
            "Preparing to unpack .../5-openjdk-8-jdk-headless_8u462-ga~us1-0ubuntu2~22.04.2_amd64.deb ...\n",
            "Unpacking openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "Setting up java-common (0.72build2) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libpcsclite1:amd64 (1.9.5-3ubuntu1) ...\n",
            "Setting up openjdk-8-jre-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/java to provide /usr/bin/java (java) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/jjs to provide /usr/bin/jjs (jjs) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/keytool to provide /usr/bin/keytool (keytool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/pack200 to provide /usr/bin/pack200 (pack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmid to provide /usr/bin/rmid (rmid) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/rmiregistry to provide /usr/bin/rmiregistry (rmiregistry) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/unpack200 to provide /usr/bin/unpack200 (unpack200) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n",
            "Setting up ca-certificates-java (20190909ubuntu1.2) ...\n",
            "head: cannot open '/etc/ssl/certs/java/cacerts' for reading: No such file or directory\n",
            "Adding debian:Amazon_Root_CA_3.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_3.pem\n",
            "Adding debian:GLOBALTRUST_2020.pem\n",
            "Adding debian:DigiCert_TLS_ECC_P384_Root_G5.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R4.pem\n",
            "Adding debian:Security_Communication_RootCA3.pem\n",
            "Adding debian:QuoVadis_Root_CA_3.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G3.pem\n",
            "Adding debian:CA_Disig_Root_R2.pem\n",
            "Adding debian:Go_Daddy_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:certSIGN_Root_CA_G2.pem\n",
            "Adding debian:Certum_EC-384_CA.pem\n",
            "Adding debian:Amazon_Root_CA_4.pem\n",
            "Adding debian:SwissSign_Silver_CA_-_G2.pem\n",
            "Adding debian:GTS_Root_R3.pem\n",
            "Adding debian:certSIGN_ROOT_CA.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_2009.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G4.pem\n",
            "Adding debian:D-TRUST_BR_Root_CA_1_2020.pem\n",
            "Adding debian:Certum_Trusted_Network_CA.pem\n",
            "Adding debian:Starfield_Services_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:GTS_Root_R4.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_G2.pem\n",
            "Adding debian:Trustwave_Global_Certification_Authority.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority_-_EC1.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_RSA.pem\n",
            "Adding debian:DigiCert_Global_Root_G3.pem\n",
            "Adding debian:GlobalSign_Root_CA.pem\n",
            "Adding debian:GDCA_TrustAUTH_R5_ROOT.pem\n",
            "Adding debian:NetLock_Arany_=Class_Gold=_Főtanúsítvány.pem\n",
            "Adding debian:Certum_Trusted_Network_CA_2.pem\n",
            "Adding debian:UCA_Extended_Validation_Root.pem\n",
            "Adding debian:emSign_Root_CA_-_C1.pem\n",
            "Adding debian:D-TRUST_Root_Class_3_CA_2_EV_2009.pem\n",
            "Adding debian:UCA_Global_G2_Root.pem\n",
            "Adding debian:QuoVadis_Root_CA_2_G3.pem\n",
            "Adding debian:ePKI_Root_Certification_Authority.pem\n",
            "Adding debian:Comodo_AAA_Services_root.pem\n",
            "Adding debian:Go_Daddy_Class_2_CA.pem\n",
            "Adding debian:COMODO_RSA_Certification_Authority.pem\n",
            "Adding debian:DigiCert_Global_Root_CA.pem\n",
            "Adding debian:DigiCert_Trusted_Root_G4.pem\n",
            "Adding debian:SwissSign_Gold_CA_-_G2.pem\n",
            "Adding debian:Certainly_Root_R1.pem\n",
            "Adding debian:vTrus_ECC_Root_CA.pem\n",
            "Adding debian:QuoVadis_Root_CA_3_G3.pem\n",
            "Adding debian:DigiCert_Global_Root_G2.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_CA.pem\n",
            "Adding debian:SSL.com_Root_Certification_Authority_ECC.pem\n",
            "Adding debian:T-TeleSec_GlobalRoot_Class_2.pem\n",
            "Adding debian:USERTrust_ECC_Certification_Authority.pem\n",
            "Adding debian:Izenpe.com.pem\n",
            "Adding debian:TUBITAK_Kamu_SM_SSL_Kok_Sertifikasi_-_Surum_1.pem\n",
            "Adding debian:GlobalSign_Root_E46.pem\n",
            "Adding debian:HARICA_TLS_RSA_Root_CA_2021.pem\n",
            "Adding debian:D-TRUST_EV_Root_CA_1_2020.pem\n",
            "Adding debian:Entrust_Root_Certification_Authority.pem\n",
            "Adding debian:HARICA_TLS_ECC_Root_CA_2021.pem\n",
            "Adding debian:Microsec_e-Szigno_Root_CA_2009.pem\n",
            "Adding debian:Amazon_Root_CA_2.pem\n",
            "Adding debian:Baltimore_CyberTrust_Root.pem\n",
            "Adding debian:ACCVRAIZ1.pem\n",
            "Adding debian:IdenTrust_Commercial_Root_CA_1.pem\n",
            "Adding debian:XRamp_Global_CA_Root.pem\n",
            "Adding debian:SZAFIR_ROOT_CA2.pem\n",
            "Adding debian:AffirmTrust_Premium.pem\n",
            "Adding debian:ANF_Secure_Server_Root_CA.pem\n",
            "Adding debian:COMODO_Certification_Authority.pem\n",
            "Adding debian:Secure_Global_CA.pem\n",
            "Adding debian:GlobalSign_ECC_Root_CA_-_R5.pem\n",
            "Adding debian:ISRG_Root_X2.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GC_CA.pem\n",
            "Adding debian:SSL.com_EV_Root_Certification_Authority_RSA_R2.pem\n",
            "Adding debian:Starfield_Class_2_CA.pem\n",
            "Adding debian:Security_Communication_ECC_RootCA1.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R3.pem\n",
            "Adding debian:Security_Communication_Root_CA.pem\n",
            "Adding debian:Microsoft_ECC_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:ISRG_Root_X1.pem\n",
            "Adding debian:AffirmTrust_Networking.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_RootCA_2015.pem\n",
            "Adding debian:OISTE_WISeKey_Global_Root_GB_CA.pem\n",
            "Adding debian:GlobalSign_Root_R46.pem\n",
            "Adding debian:e-Szigno_Root_CA_2017.pem\n",
            "Adding debian:Certigna.pem\n",
            "Adding debian:Buypass_Class_3_Root_CA.pem\n",
            "Adding debian:Entrust.net_Premium_2048_Secure_Server_CA.pem\n",
            "Adding debian:Actalis_Authentication_Root_CA.pem\n",
            "Adding debian:SecureTrust_CA.pem\n",
            "Adding debian:Certainly_Root_E1.pem\n",
            "Adding debian:DigiCert_TLS_RSA4096_Root_G5.pem\n",
            "Adding debian:Atos_TrustedRoot_2011.pem\n",
            "Adding debian:DigiCert_High_Assurance_EV_Root_CA.pem\n",
            "Adding debian:GTS_Root_R2.pem\n",
            "Adding debian:CFCA_EV_ROOT.pem\n",
            "Adding debian:Security_Communication_RootCA2.pem\n",
            "Adding debian:GlobalSign_Root_CA_-_R6.pem\n",
            "Adding debian:Trustwave_Global_ECC_P256_Certification_Authority.pem\n",
            "Adding debian:Autoridad_de_Certificacion_Firmaprofesional_CIF_A62634068.pem\n",
            "Adding debian:AffirmTrust_Commercial.pem\n",
            "Adding debian:emSign_Root_CA_-_G1.pem\n",
            "Adding debian:DigiCert_Assured_ID_Root_G2.pem\n",
            "Adding debian:TWCA_Global_Root_CA.pem\n",
            "Adding debian:Certigna_Root_CA.pem\n",
            "Adding debian:USERTrust_RSA_Certification_Authority.pem\n",
            "Adding debian:Amazon_Root_CA_1.pem\n",
            "Adding debian:Buypass_Class_2_Root_CA.pem\n",
            "Adding debian:NAVER_Global_Root_Certification_Authority.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_C3.pem\n",
            "Adding debian:Microsoft_RSA_Root_Certificate_Authority_2017.pem\n",
            "Adding debian:Hongkong_Post_Root_CA_3.pem\n",
            "Adding debian:IdenTrust_Public_Sector_Root_CA_1.pem\n",
            "Adding debian:emSign_ECC_Root_CA_-_G3.pem\n",
            "Adding debian:GTS_Root_R1.pem\n",
            "Adding debian:Certum_Trusted_Root_CA.pem\n",
            "Adding debian:Trustwave_Global_ECC_P384_Certification_Authority.pem\n",
            "Adding debian:vTrus_Root_CA.pem\n",
            "Adding debian:HiPKI_Root_CA_-_G1.pem\n",
            "Adding debian:TWCA_Root_Certification_Authority.pem\n",
            "Adding debian:AffirmTrust_Premium_ECC.pem\n",
            "Adding debian:Hellenic_Academic_and_Research_Institutions_ECC_RootCA_2015.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM.pem\n",
            "Adding debian:AC_RAIZ_FNMT-RCM_SERVIDORES_SEGUROS.pem\n",
            "Adding debian:SecureSign_RootCA11.pem\n",
            "Adding debian:TunTrust_Root_CA.pem\n",
            "Adding debian:Telia_Root_CA_v2.pem\n",
            "Adding debian:TeliaSonera_Root_CA_v1.pem\n",
            "Adding debian:QuoVadis_Root_CA_1_G3.pem\n",
            "Adding debian:COMODO_ECC_Certification_Authority.pem\n",
            "Adding debian:QuoVadis_Root_CA_2.pem\n",
            "Adding debian:Starfield_Root_Certificate_Authority_-_G2.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-01.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_E46.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_RSA_TLS_2021.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G3.pem\n",
            "Adding debian:Sectigo_Public_Server_Authentication_Root_R46.pem\n",
            "Adding debian:TrustAsia_Global_Root_CA_G4.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-01.pem\n",
            "Adding debian:SSL.com_TLS_RSA_Root_CA_2022.pem\n",
            "Adding debian:BJCA_Global_Root_CA1.pem\n",
            "Adding debian:CommScope_Public_Trust_ECC_Root-02.pem\n",
            "Adding debian:Atos_TrustedRoot_Root_CA_ECC_TLS_2021.pem\n",
            "Adding debian:CommScope_Public_Trust_RSA_Root-02.pem\n",
            "Adding debian:BJCA_Global_Root_CA2.pem\n",
            "Adding debian:SSL.com_TLS_ECC_Root_CA_2022.pem\n",
            "done.\n",
            "Setting up openjdk-8-jdk-headless:amd64 (8u462-ga~us1-0ubuntu2~22.04.2) ...\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jar to provide /usr/bin/jar (jar) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jarsigner to provide /usr/bin/jarsigner (jarsigner) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javac to provide /usr/bin/javac (javac) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javadoc to provide /usr/bin/javadoc (javadoc) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javap to provide /usr/bin/javap (javap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jcmd to provide /usr/bin/jcmd (jcmd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdb to provide /usr/bin/jdb (jdb) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jdeps to provide /usr/bin/jdeps (jdeps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jfr to provide /usr/bin/jfr (jfr) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jinfo to provide /usr/bin/jinfo (jinfo) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jmap to provide /usr/bin/jmap (jmap) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jps to provide /usr/bin/jps (jps) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jrunscript to provide /usr/bin/jrunscript (jrunscript) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstack to provide /usr/bin/jstack (jstack) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstat to provide /usr/bin/jstat (jstat) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jstatd to provide /usr/bin/jstatd (jstatd) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/rmic to provide /usr/bin/rmic (rmic) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/serialver to provide /usr/bin/serialver (serialver) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n",
            "update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for ca-certificates (20240203~22.04.1) ...\n",
            "Updating certificates in /etc/ssl/certs...\n",
            "0 added, 0 removed; done.\n",
            "Running hooks in /etc/ca-certificates/update.d...\n",
            "\n",
            "done.\n",
            "done.\n",
            "openjdk version \"1.8.0_462\"\n",
            "OpenJDK Runtime Environment (build 1.8.0_462-8u462-ga~us1-0ubuntu2~22.04.2-b08)\n",
            "OpenJDK 64-Bit Server VM (build 25.462-b08, mixed mode)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btsOPcRh24-I",
        "outputId": "064007ed-2391-44fa-cb5a-d62da3b6033a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lab 5 Spark: Advanced Sentiment Analysis with PySpark\n",
        "This file demonstrates how to build a text classification pipeline using Apache Spark\n",
        "for handling large-scale datasets that don't fit into a single machine's memory.\n",
        "\"\"\"\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "import os\n",
        "\n",
        "\n",
        "def create_sample_data(spark, output_path=\"data/sentiments.csv\"):\n",
        "    \"\"\"\n",
        "    Create a sample sentiments dataset for demonstration.\n",
        "\n",
        "    Args:\n",
        "        spark: SparkSession instance\n",
        "        output_path: Path to save the CSV file\n",
        "    \"\"\"\n",
        "    # Sample data with sentiment labels (-1 for negative, 1 for positive)\n",
        "    data = [\n",
        "        (\"This movie is fantastic and I love it!\", 1),\n",
        "        (\"I hate this film, it's terrible.\", -1),\n",
        "        (\"The acting was superb, a truly great experience.\", 1),\n",
        "        (\"What a waste of time, absolutely boring.\", -1),\n",
        "        (\"Highly recommend this, a masterpiece.\", 1),\n",
        "        (\"Could not finish watching, so bad.\", -1),\n",
        "        (\"Amazing storyline, kept me engaged throughout.\", 1),\n",
        "        (\"Disappointing and poorly executed.\", -1),\n",
        "        (\"Brilliant cinematography and great performances.\", 1),\n",
        "        (\"Not worth watching, very dull.\", -1),\n",
        "        (\"Exceptional movie, one of the best I've seen.\", 1),\n",
        "        (\"Awful, I regret watching this.\", -1),\n",
        "        (\"Wonderful experience, loved every scene.\", 1),\n",
        "        (\"Boring and predictable plot.\", -1),\n",
        "        (\"Outstanding film with excellent direction.\", 1),\n",
        "        (\"Terrible waste of money and time.\", -1),\n",
        "        (\"Incredible acting and beautiful visuals.\", 1),\n",
        "        (\"So bad, couldn't watch till the end.\", -1),\n",
        "        (\"Superb entertainment, highly enjoyable.\", 1),\n",
        "        (\"Worst movie ever, absolutely horrible.\", -1),\n",
        "        (\"Compelling story with emotional depth.\", 1),\n",
        "        (\"Poorly written and badly directed.\", -1),\n",
        "        (\"Captivating from start to finish.\", 1),\n",
        "        (\"Complete disaster, very disappointing.\", -1),\n",
        "        (\"Excellent performances all around.\", 1),\n",
        "        (\"Waste of time, not recommended.\", -1),\n",
        "        (\"Beautiful cinematography and soundtrack.\", 1),\n",
        "        (\"Dull and uninspiring movie.\", -1),\n",
        "        (\"Must watch, absolutely brilliant.\", 1),\n",
        "        (\"Horrible experience, very bad.\", -1),\n",
        "    ]\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = spark.createDataFrame(data, [\"text\", \"sentiment\"])\n",
        "\n",
        "    # Save to CSV\n",
        "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
        "    df.coalesce(1).write.csv(output_path, header=True, mode=\"overwrite\")\n",
        "    print(f\"✓ Sample data created at: {output_path}\")\n",
        "\n",
        "    return output_path\n",
        "\n",
        "\n",
        "def check_java_installation():\n",
        "    \"\"\"\n",
        "    Check if Java is installed and set up JAVA_HOME if needed.\n",
        "    \"\"\"\n",
        "    import subprocess\n",
        "    import sys\n",
        "\n",
        "    try:\n",
        "        # Check if Java is installed\n",
        "        result = subprocess.run(['java', '-version'],\n",
        "                              capture_output=True,\n",
        "                              text=True,\n",
        "                              timeout=5)\n",
        "        if result.returncode == 0:\n",
        "            print(\"✓ Java is installed\")\n",
        "            return True\n",
        "    except (FileNotFoundError, subprocess.TimeoutExpired):\n",
        "        pass\n",
        "\n",
        "    # Try to install Java on Colab\n",
        "    print(\"⚠ Java not found. Installing Java...\")\n",
        "    try:\n",
        "        subprocess.run(['apt-get', 'update'], check=True, capture_output=True)\n",
        "        subprocess.run(['apt-get', 'install', '-y', 'openjdk-8-jdk-headless'],\n",
        "                      check=True, capture_output=True)\n",
        "\n",
        "        # Set JAVA_HOME\n",
        "        os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "        print(\"✓ Java installed successfully\")\n",
        "        return True\n",
        "    except:\n",
        "        print(\"✗ Failed to install Java automatically\")\n",
        "        print(\"\\nPlease run these commands in a Colab cell:\")\n",
        "        print(\"!apt-get update\")\n",
        "        print(\"!apt-get install -y openjdk-8-jdk-headless\")\n",
        "        print(\"import os\")\n",
        "        print(\"os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\")\n",
        "        return False\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run PySpark sentiment analysis pipeline.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"PYSPARK SENTIMENT ANALYSIS PIPELINE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Check Java installation\n",
        "    print(\"\\nChecking Java installation...\")\n",
        "    print(\"-\" * 80)\n",
        "    if not check_java_installation():\n",
        "        print(\"\\n✗ Cannot proceed without Java. Please install Java first.\")\n",
        "        return\n",
        "\n",
        "    # Step 1: Initialize Spark Session\n",
        "    print(\"\\nStep 1: Initialize Spark Session\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    try:\n",
        "        spark = SparkSession.builder \\\n",
        "            .appName(\"SentimentAnalysis\") \\\n",
        "            .master(\"local[*]\") \\\n",
        "            .config(\"spark.driver.memory\", \"2g\") \\\n",
        "            .config(\"spark.driver.host\", \"127.0.0.1\") \\\n",
        "            .getOrCreate()\n",
        "\n",
        "        # Set log level to reduce verbosity\n",
        "        spark.sparkContext.setLogLevel(\"ERROR\")\n",
        "        print(\"✓ Spark Session initialized\")\n",
        "        print(f\"  - App Name: SentimentAnalysis\")\n",
        "        print(f\"  - Spark Version: {spark.version}\")\n",
        "    except Exception as e:\n",
        "        print(f\"✗ Failed to initialize Spark Session: {str(e)}\")\n",
        "        print(\"\\nTroubleshooting tips:\")\n",
        "        print(\"1. Make sure Java 8 or 11 is installed\")\n",
        "        print(\"2. Set JAVA_HOME environment variable\")\n",
        "        print(\"3. Try running: !apt-get install -y openjdk-8-jdk-headless\")\n",
        "        return\n",
        "\n",
        "    # Step 2: Load Data\n",
        "    print(\"\\nStep 2: Load Data\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    data_path = \"data/sentiments.csv\"\n",
        "\n",
        "    # Create sample data if it doesn't exist\n",
        "    if not os.path.exists(data_path):\n",
        "        print(\"Creating sample dataset...\")\n",
        "        create_sample_data(spark, data_path)\n",
        "\n",
        "    # Read the CSV file\n",
        "    # Note: Since we used coalesce(1), there will be a part file inside the directory\n",
        "    try:\n",
        "        df = spark.read.csv(data_path, header=True, inferSchema=True)\n",
        "    except:\n",
        "        # If direct read fails, try reading from the directory\n",
        "        df = spark.read.csv(f\"{data_path}/*.csv\", header=True, inferSchema=True)\n",
        "\n",
        "    print(f\"✓ Data loaded from: {data_path}\")\n",
        "\n",
        "    # Show initial row count\n",
        "    initial_row_count = df.count()\n",
        "    print(f\"  - Total rows: {initial_row_count}\")\n",
        "\n",
        "    # Show schema\n",
        "    print(\"\\nDataset Schema:\")\n",
        "    df.printSchema()\n",
        "\n",
        "    # Show sample data\n",
        "    print(\"\\nSample Data (first 5 rows):\")\n",
        "    df.show(5, truncate=50)\n",
        "\n",
        "    # Drop rows with null sentiment values\n",
        "    df = df.dropna(subset=[\"sentiment\"])\n",
        "    rows_after_drop = df.count()\n",
        "    print(f\"\\n✓ Dropped {initial_row_count - rows_after_drop} rows with null sentiments\")\n",
        "\n",
        "    # Convert -1/1 labels to 0/1 for binary classification\n",
        "    df = df.withColumn(\"label\", (col(\"sentiment\").cast(\"integer\") + 1) / 2)\n",
        "    print(\"✓ Converted sentiment labels: -1 → 0 (negative), 1 → 1 (positive)\")\n",
        "\n",
        "    # Show label distribution\n",
        "    print(\"\\nLabel Distribution:\")\n",
        "    df.groupBy(\"label\").count().show()\n",
        "\n",
        "    # Step 3: Split Data\n",
        "    print(\"\\nStep 3: Split Data into Training and Test Sets\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Split data: 80% training, 20% testing\n",
        "    trainingData, testData = df.randomSplit([0.8, 0.2], seed=42)\n",
        "\n",
        "    train_count = trainingData.count()\n",
        "    test_count = testData.count()\n",
        "\n",
        "    print(f\"✓ Training set: {train_count} samples ({train_count/rows_after_drop*100:.1f}%)\")\n",
        "    print(f\"✓ Test set: {test_count} samples ({test_count/rows_after_drop*100:.1f}%)\")\n",
        "\n",
        "    # Step 4: Build Preprocessing Pipeline\n",
        "    print(\"\\nStep 4: Build Preprocessing Pipeline\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Tokenizer: Splits text into words\n",
        "    tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "    print(\"✓ Tokenizer: Splits text into words\")\n",
        "\n",
        "    # StopWordsRemover: Removes common stop words\n",
        "    stopwordsRemover = StopWordsRemover(\n",
        "        inputCol=\"words\",\n",
        "        outputCol=\"filtered_words\"\n",
        "    )\n",
        "    print(\"✓ StopWordsRemover: Removes common stop words\")\n",
        "\n",
        "    # HashingTF: Converts tokens into feature vectors using hashing\n",
        "    hashingTF = HashingTF(\n",
        "        inputCol=\"filtered_words\",\n",
        "        outputCol=\"raw_features\",\n",
        "        numFeatures=10000\n",
        "    )\n",
        "    print(\"✓ HashingTF: Converts tokens to feature vectors (10,000 features)\")\n",
        "\n",
        "    # IDF: Inverse Document Frequency - rescales feature vectors\n",
        "    idf = IDF(\n",
        "        inputCol=\"raw_features\",\n",
        "        outputCol=\"features\"\n",
        "    )\n",
        "    print(\"✓ IDF: Rescales features using inverse document frequency\")\n",
        "\n",
        "    # Step 5: Train the Model\n",
        "    print(\"\\nStep 5: Initialize Logistic Regression Model\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # LogisticRegression: Binary classification model\n",
        "    lr = LogisticRegression(\n",
        "        maxIter=10,\n",
        "        regParam=0.001,\n",
        "        featuresCol=\"features\",\n",
        "        labelCol=\"label\"\n",
        "    )\n",
        "    print(\"✓ Logistic Regression initialized\")\n",
        "    print(f\"  - Max Iterations: 10\")\n",
        "    print(f\"  - Regularization Parameter: 0.001\")\n",
        "\n",
        "    # Assemble the Pipeline\n",
        "    print(\"\\nStep 6: Assemble and Train Pipeline\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    pipeline = Pipeline(stages=[tokenizer, stopwordsRemover, hashingTF, idf, lr])\n",
        "    print(\"✓ Pipeline created with 5 stages:\")\n",
        "    print(\"  1. Tokenizer\")\n",
        "    print(\"  2. StopWordsRemover\")\n",
        "    print(\"  3. HashingTF\")\n",
        "    print(\"  4. IDF\")\n",
        "    print(\"  5. LogisticRegression\")\n",
        "\n",
        "    # Train the model\n",
        "    print(\"\\nTraining model (this may take a moment)...\")\n",
        "    model = pipeline.fit(trainingData)\n",
        "    print(\"✓ Model trained successfully!\")\n",
        "\n",
        "    # Step 6: Make Predictions\n",
        "    print(\"\\nStep 7: Make Predictions on Test Data\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    predictions = model.transform(testData)\n",
        "    print(\"✓ Predictions generated\")\n",
        "\n",
        "    # Show predictions\n",
        "    print(\"\\nSample Predictions (first 5 rows):\")\n",
        "    predictions.select(\"text\", \"label\", \"prediction\", \"probability\").show(5, truncate=50)\n",
        "\n",
        "    # Step 7: Evaluate the Model\n",
        "    print(\"\\nStep 8: Evaluate Model Performance\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Accuracy\n",
        "    evaluator_accuracy = MulticlassClassificationEvaluator(\n",
        "        labelCol=\"label\",\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"accuracy\"\n",
        "    )\n",
        "    accuracy = evaluator_accuracy.evaluate(predictions)\n",
        "    print(f\"✓ Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # F1 Score\n",
        "    evaluator_f1 = MulticlassClassificationEvaluator(\n",
        "        labelCol=\"label\",\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"f1\"\n",
        "    )\n",
        "    f1 = evaluator_f1.evaluate(predictions)\n",
        "    print(f\"✓ F1 Score: {f1:.4f}\")\n",
        "\n",
        "    # Precision\n",
        "    evaluator_precision = MulticlassClassificationEvaluator(\n",
        "        labelCol=\"label\",\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"weightedPrecision\"\n",
        "    )\n",
        "    precision = evaluator_precision.evaluate(predictions)\n",
        "    print(f\"✓ Weighted Precision: {precision:.4f}\")\n",
        "\n",
        "    # Recall\n",
        "    evaluator_recall = MulticlassClassificationEvaluator(\n",
        "        labelCol=\"label\",\n",
        "        predictionCol=\"prediction\",\n",
        "        metricName=\"weightedRecall\"\n",
        "    )\n",
        "    recall = evaluator_recall.evaluate(predictions)\n",
        "    print(f\"✓ Weighted Recall: {recall:.4f}\")\n",
        "\n",
        "    # Confusion Matrix (manual calculation)\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    # Calculate confusion matrix components\n",
        "    tp = predictions.filter((col(\"label\") == 1) & (col(\"prediction\") == 1)).count()\n",
        "    tn = predictions.filter((col(\"label\") == 0) & (col(\"prediction\") == 0)).count()\n",
        "    fp = predictions.filter((col(\"label\") == 0) & (col(\"prediction\") == 1)).count()\n",
        "    fn = predictions.filter((col(\"label\") == 1) & (col(\"prediction\") == 0)).count()\n",
        "\n",
        "    print(f\"                Predicted\")\n",
        "    print(f\"                Neg (0)  Pos (1)\")\n",
        "    print(f\"Actual  Neg (0)   {tn:3d}      {fp:3d}\")\n",
        "    print(f\"        Pos (1)   {fn:3d}      {tp:3d}\")\n",
        "\n",
        "    # Test on new data\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"BONUS: Test Pipeline on New Unseen Data\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    new_data = [\n",
        "        (\"This is an amazing film, loved every minute!\",),\n",
        "        (\"Terrible movie, don't waste your money.\",),\n",
        "        (\"Outstanding performance by the actors.\",),\n",
        "        (\"Very disappointing, expected much better.\",),\n",
        "        (\"Absolute masterpiece, beautifully crafted.\",)\n",
        "    ]\n",
        "\n",
        "    new_df = spark.createDataFrame(new_data, [\"text\"])\n",
        "    new_predictions = model.transform(new_df)\n",
        "\n",
        "    print(\"\\nPredictions on New Data:\")\n",
        "    result = new_predictions.select(\"text\", \"prediction\", \"probability\").collect()\n",
        "\n",
        "    for i, row in enumerate(result, 1):\n",
        "        sentiment = \"Positive 😊\" if row[\"prediction\"] == 1.0 else \"Negative 😞\"\n",
        "        confidence = max(row[\"probability\"].toArray()) * 100\n",
        "        print(f\"\\n{i}. [{sentiment}] (Confidence: {confidence:.1f}%)\")\n",
        "        print(f\"   Text: '{row['text']}'\")\n",
        "\n",
        "    # Stop Spark Session\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Stopping Spark Session...\")\n",
        "    spark.stop()\n",
        "    print(\"✓ Spark Session stopped\")\n",
        "    print(\"=\" * 80)\n",
        "    print(\"PYSPARK SENTIMENT ANALYSIS COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjugxNcW2m5b",
        "outputId": "0cabd9b5-b987-45a3-bcd1-953bc9f1e0a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "PYSPARK SENTIMENT ANALYSIS PIPELINE\n",
            "================================================================================\n",
            "\n",
            "Checking Java installation...\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Java is installed\n",
            "\n",
            "Step 1: Initialize Spark Session\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Spark Session initialized\n",
            "  - App Name: SentimentAnalysis\n",
            "  - Spark Version: 3.5.1\n",
            "\n",
            "Step 2: Load Data\n",
            "--------------------------------------------------------------------------------\n",
            "Creating sample dataset...\n",
            "✓ Sample data created at: data/sentiments.csv\n",
            "✓ Data loaded from: data/sentiments.csv\n",
            "  - Total rows: 30\n",
            "\n",
            "Dataset Schema:\n",
            "root\n",
            " |-- text: string (nullable = true)\n",
            " |-- sentiment: integer (nullable = true)\n",
            "\n",
            "\n",
            "Sample Data (first 5 rows):\n",
            "+------------------------------------------------+---------+\n",
            "|                                            text|sentiment|\n",
            "+------------------------------------------------+---------+\n",
            "|          This movie is fantastic and I love it!|        1|\n",
            "|                I hate this film, it's terrible.|       -1|\n",
            "|The acting was superb, a truly great experience.|        1|\n",
            "|        What a waste of time, absolutely boring.|       -1|\n",
            "|           Highly recommend this, a masterpiece.|        1|\n",
            "+------------------------------------------------+---------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "✓ Dropped 0 rows with null sentiments\n",
            "✓ Converted sentiment labels: -1 → 0 (negative), 1 → 1 (positive)\n",
            "\n",
            "Label Distribution:\n",
            "+-----+-----+\n",
            "|label|count|\n",
            "+-----+-----+\n",
            "|  0.0|   15|\n",
            "|  1.0|   15|\n",
            "+-----+-----+\n",
            "\n",
            "\n",
            "Step 3: Split Data into Training and Test Sets\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Training set: 23 samples (76.7%)\n",
            "✓ Test set: 7 samples (23.3%)\n",
            "\n",
            "Step 4: Build Preprocessing Pipeline\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Tokenizer: Splits text into words\n",
            "✓ StopWordsRemover: Removes common stop words\n",
            "✓ HashingTF: Converts tokens to feature vectors (10,000 features)\n",
            "✓ IDF: Rescales features using inverse document frequency\n",
            "\n",
            "Step 5: Initialize Logistic Regression Model\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Logistic Regression initialized\n",
            "  - Max Iterations: 10\n",
            "  - Regularization Parameter: 0.001\n",
            "\n",
            "Step 6: Assemble and Train Pipeline\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Pipeline created with 5 stages:\n",
            "  1. Tokenizer\n",
            "  2. StopWordsRemover\n",
            "  3. HashingTF\n",
            "  4. IDF\n",
            "  5. LogisticRegression\n",
            "\n",
            "Training model (this may take a moment)...\n",
            "✓ Model trained successfully!\n",
            "\n",
            "Step 7: Make Predictions on Test Data\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Predictions generated\n",
            "\n",
            "Sample Predictions (first 5 rows):\n",
            "+------------------------------------------+-----+----------+-----------------------------------------+\n",
            "|                                      text|label|prediction|                              probability|\n",
            "+------------------------------------------+-----+----------+-----------------------------------------+\n",
            "|  Beautiful cinematography and soundtrack.|  1.0|       1.0|[0.060462980743312154,0.9395370192566879]|\n",
            "|    Compelling story with emotional depth.|  1.0|       0.0|  [0.7281235190906735,0.2718764809093265]|\n",
            "|        Could not finish watching, so bad.|  0.0|       0.0|[0.9941815037362236,0.005818496263776396]|\n",
            "|     Highly recommend this, a masterpiece.|  1.0|       1.0|  [0.3004602376858176,0.6995397623141824]|\n",
            "|Outstanding film with excellent direction.|  1.0|       1.0| [0.20304285549681542,0.7969571445031846]|\n",
            "+------------------------------------------+-----+----------+-----------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "\n",
            "Step 8: Evaluate Model Performance\n",
            "--------------------------------------------------------------------------------\n",
            "✓ Accuracy: 0.7143\n",
            "✓ F1 Score: 0.7143\n",
            "✓ Weighted Precision: 0.7143\n",
            "✓ Weighted Recall: 0.7143\n",
            "\n",
            "Confusion Matrix:\n",
            "--------------------------------------------------------------------------------\n",
            "                Predicted\n",
            "                Neg (0)  Pos (1)\n",
            "Actual  Neg (0)     2        1\n",
            "        Pos (1)     1        3\n",
            "\n",
            "================================================================================\n",
            "BONUS: Test Pipeline on New Unseen Data\n",
            "================================================================================\n",
            "\n",
            "Predictions on New Data:\n",
            "\n",
            "1. [Positive 😊] (Confidence: 92.6%)\n",
            "   Text: 'This is an amazing film, loved every minute!'\n",
            "\n",
            "2. [Negative 😞] (Confidence: 78.9%)\n",
            "   Text: 'Terrible movie, don't waste your money.'\n",
            "\n",
            "3. [Negative 😞] (Confidence: 72.8%)\n",
            "   Text: 'Outstanding performance by the actors.'\n",
            "\n",
            "4. [Negative 😞] (Confidence: 72.8%)\n",
            "   Text: 'Very disappointing, expected much better.'\n",
            "\n",
            "5. [Negative 😞] (Confidence: 72.8%)\n",
            "   Text: 'Absolute masterpiece, beautifully crafted.'\n",
            "\n",
            "================================================================================\n",
            "Stopping Spark Session...\n",
            "✓ Spark Session stopped\n",
            "================================================================================\n",
            "PYSPARK SENTIMENT ANALYSIS COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Lab Task 4: Evaluating and Improving Model Performance\n",
        "\n",
        "This module demonstrates various techniques to improve text classification performance:\n",
        "1. Improved preprocessing and feature selection\n",
        "2. Advanced embedding methods (Word2Vec)\n",
        "3. Multiple model architectures (Naive Bayes, Random Forest, Gradient Boosting)\n",
        "\"\"\"\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "class AdvancedTextPreprocessor:\n",
        "    \"\"\"\n",
        "    Advanced text preprocessor with noise filtering and vocabulary reduction.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, remove_urls=True, remove_special_chars=True,\n",
        "                 min_word_length=2, lowercase=True):\n",
        "        \"\"\"\n",
        "        Initialize the preprocessor with various options.\n",
        "\n",
        "        Args:\n",
        "            remove_urls: Remove URLs from text\n",
        "            remove_special_chars: Remove special characters\n",
        "            min_word_length: Minimum word length to keep\n",
        "            lowercase: Convert text to lowercase\n",
        "        \"\"\"\n",
        "        self.remove_urls = remove_urls\n",
        "        self.remove_special_chars = remove_special_chars\n",
        "        self.min_word_length = min_word_length\n",
        "        self.lowercase = lowercase\n",
        "\n",
        "    def clean_text(self, text: str) -> str:\n",
        "        \"\"\"\n",
        "        Clean and preprocess text.\n",
        "\n",
        "        Args:\n",
        "            text: Input text\n",
        "\n",
        "        Returns:\n",
        "            Cleaned text\n",
        "        \"\"\"\n",
        "        # Lowercase\n",
        "        if self.lowercase:\n",
        "            text = text.lower()\n",
        "\n",
        "        # Remove URLs\n",
        "        if self.remove_urls:\n",
        "            text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "\n",
        "        # Remove HTML tags\n",
        "        text = re.sub(r'<.*?>', '', text)\n",
        "\n",
        "        # Remove special characters but keep spaces\n",
        "        if self.remove_special_chars:\n",
        "            text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "\n",
        "        # Remove extra whitespace\n",
        "        text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "        # Remove short words\n",
        "        words = text.split()\n",
        "        words = [w for w in words if len(w) >= self.min_word_length]\n",
        "        text = ' '.join(words)\n",
        "\n",
        "        return text\n",
        "\n",
        "    def preprocess_corpus(self, texts: List[str]) -> List[str]:\n",
        "        \"\"\"\n",
        "        Preprocess a list of texts.\n",
        "\n",
        "        Args:\n",
        "            texts: List of texts\n",
        "\n",
        "        Returns:\n",
        "            List of cleaned texts\n",
        "        \"\"\"\n",
        "        return [self.clean_text(text) for text in texts]\n",
        "\n",
        "\n",
        "class ImprovedTextClassifier:\n",
        "    \"\"\"\n",
        "    Improved text classifier with multiple model options and advanced features.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vectorizer, model_type='logistic_regression', **model_params):\n",
        "        \"\"\"\n",
        "        Initialize the classifier.\n",
        "\n",
        "        Args:\n",
        "            vectorizer: Vectorizer instance (TfidfVectorizer or CountVectorizer)\n",
        "            model_type: Type of model ('logistic_regression', 'naive_bayes',\n",
        "                       'random_forest', 'gradient_boosting')\n",
        "            **model_params: Additional parameters for the model\n",
        "        \"\"\"\n",
        "        self.vectorizer = vectorizer\n",
        "        self.model_type = model_type\n",
        "        self.model_params = model_params\n",
        "        self._model = None\n",
        "\n",
        "        # Initialize model based on type\n",
        "        self._init_model()\n",
        "\n",
        "    def _init_model(self):\n",
        "        \"\"\"Initialize the classification model based on model_type.\"\"\"\n",
        "        if self.model_type == 'logistic_regression':\n",
        "            default_params = {'solver': 'liblinear', 'random_state': 42}\n",
        "            default_params.update(self.model_params)\n",
        "            self._model = LogisticRegression(**default_params)\n",
        "\n",
        "        elif self.model_type == 'naive_bayes':\n",
        "            self._model = MultinomialNB(**self.model_params)\n",
        "\n",
        "        elif self.model_type == 'random_forest':\n",
        "            default_params = {'n_estimators': 100, 'random_state': 42}\n",
        "            default_params.update(self.model_params)\n",
        "            self._model = RandomForestClassifier(**default_params)\n",
        "\n",
        "        elif self.model_type == 'gradient_boosting':\n",
        "            default_params = {'n_estimators': 100, 'random_state': 42}\n",
        "            default_params.update(self.model_params)\n",
        "            self._model = GradientBoostingClassifier(**default_params)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown model type: {self.model_type}\")\n",
        "\n",
        "    def fit(self, texts: List[str], labels: List[int]):\n",
        "        \"\"\"Train the classifier.\"\"\"\n",
        "        X = self.vectorizer.fit_transform(texts)\n",
        "        self._model.fit(X, labels)\n",
        "        return self\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[int]:\n",
        "        \"\"\"Predict labels for new texts.\"\"\"\n",
        "        X = self.vectorizer.transform(texts)\n",
        "        predictions = self._model.predict(X)\n",
        "        return predictions.tolist()\n",
        "\n",
        "    def predict_proba(self, texts: List[str]) -> np.ndarray:\n",
        "        \"\"\"Predict probabilities for each class.\"\"\"\n",
        "        X = self.vectorizer.transform(texts)\n",
        "        if hasattr(self._model, 'predict_proba'):\n",
        "            return self._model.predict_proba(X)\n",
        "        else:\n",
        "            raise ValueError(f\"Model {self.model_type} doesn't support predict_proba\")\n",
        "\n",
        "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate the model's predictions.\"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "        return metrics\n",
        "\n",
        "    def cross_validate(self, texts: List[str], labels: List[int], cv=5) -> Dict[str, float]:\n",
        "        \"\"\"Perform cross-validation.\"\"\"\n",
        "        X = self.vectorizer.fit_transform(texts)\n",
        "        scores = cross_val_score(self._model, X, labels, cv=cv, scoring='f1')\n",
        "        return {\n",
        "            'mean_f1': scores.mean(),\n",
        "            'std_f1': scores.std(),\n",
        "            'scores': scores.tolist()\n",
        "        }\n",
        "\n",
        "\n",
        "class SimpleWord2VecClassifier:\n",
        "    \"\"\"\n",
        "    A simple Word2Vec-based classifier using averaged word embeddings.\n",
        "    Note: For production use, consider using gensim's Word2Vec or pre-trained embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, embedding_dim=100, model_type='logistic_regression'):\n",
        "        \"\"\"\n",
        "        Initialize Word2Vec classifier.\n",
        "\n",
        "        Args:\n",
        "            embedding_dim: Dimension of word embeddings\n",
        "            model_type: Type of classifier to use\n",
        "        \"\"\"\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.model_type = model_type\n",
        "        self.word_vectors = {}\n",
        "        self._model = None\n",
        "\n",
        "        if model_type == 'logistic_regression':\n",
        "            self._model = LogisticRegression(solver='liblinear', random_state=42)\n",
        "        elif model_type == 'gradient_boosting':\n",
        "            self._model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "    def _build_vocabulary(self, texts: List[str]):\n",
        "        \"\"\"Build vocabulary from texts.\"\"\"\n",
        "        vocab = set()\n",
        "        for text in texts:\n",
        "            words = text.lower().split()\n",
        "            vocab.update(words)\n",
        "        return list(vocab)\n",
        "\n",
        "    def _initialize_embeddings(self, vocab: List[str]):\n",
        "        \"\"\"Initialize random word embeddings (simplified version).\"\"\"\n",
        "        np.random.seed(42)\n",
        "        for word in vocab:\n",
        "            self.word_vectors[word] = np.random.randn(self.embedding_dim) * 0.1\n",
        "\n",
        "    def _text_to_vector(self, text: str) -> np.ndarray:\n",
        "        \"\"\"Convert text to averaged word vector.\"\"\"\n",
        "        words = text.lower().split()\n",
        "        vectors = [self.word_vectors.get(word, np.zeros(self.embedding_dim))\n",
        "                  for word in words if word in self.word_vectors]\n",
        "\n",
        "        if not vectors:\n",
        "            return np.zeros(self.embedding_dim)\n",
        "\n",
        "        return np.mean(vectors, axis=0)\n",
        "\n",
        "    def fit(self, texts: List[str], labels: List[int]):\n",
        "        \"\"\"Train the classifier.\"\"\"\n",
        "        # Build vocabulary and initialize embeddings\n",
        "        vocab = self._build_vocabulary(texts)\n",
        "        self._initialize_embeddings(vocab)\n",
        "\n",
        "        # Convert texts to vectors\n",
        "        X = np.array([self._text_to_vector(text) for text in texts])\n",
        "\n",
        "        # Train model\n",
        "        self._model.fit(X, labels)\n",
        "        return self\n",
        "\n",
        "    def predict(self, texts: List[str]) -> List[int]:\n",
        "        \"\"\"Predict labels for new texts.\"\"\"\n",
        "        X = np.array([self._text_to_vector(text) for text in texts])\n",
        "        predictions = self._model.predict(X)\n",
        "        return predictions.tolist()\n",
        "\n",
        "    def evaluate(self, y_true: List[int], y_pred: List[int]) -> Dict[str, float]:\n",
        "        \"\"\"Evaluate predictions.\"\"\"\n",
        "        metrics = {\n",
        "            'accuracy': accuracy_score(y_true, y_pred),\n",
        "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
        "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
        "            'f1_score': f1_score(y_true, y_pred, zero_division=0)\n",
        "        }\n",
        "        return metrics\n",
        "\n",
        "\n",
        "def compare_models(X_train, X_test, y_train, y_test) -> Dict:\n",
        "    \"\"\"\n",
        "    Compare different model architectures.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with results for each model\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    model_configs = {\n",
        "        'Logistic Regression': ('logistic_regression', {}),\n",
        "        'Naive Bayes': ('naive_bayes', {}),\n",
        "        'Random Forest': ('random_forest', {}),\n",
        "        'Gradient Boosting': ('gradient_boosting', {})\n",
        "    }\n",
        "\n",
        "    for model_name, (model_type, params) in model_configs.items():\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "\n",
        "        # Create vectorizer for each model\n",
        "        vectorizer = TfidfVectorizer(\n",
        "            max_features=1000,\n",
        "            ngram_range=(1, 2),\n",
        "            min_df=2,\n",
        "            stop_words='english'\n",
        "        )\n",
        "\n",
        "        # Create and train classifier\n",
        "        classifier = ImprovedTextClassifier(vectorizer, model_type, **params)\n",
        "        classifier.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = classifier.predict(X_test)\n",
        "\n",
        "        # Evaluate\n",
        "        metrics = classifier.evaluate(y_test, y_pred)\n",
        "        results[model_name] = metrics\n",
        "\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f}\")\n",
        "        print(f\"  F1 Score: {metrics['f1_score']:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function demonstrating all improvement techniques.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"TASK 4: EVALUATING AND IMPROVING MODEL PERFORMANCE\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Extended dataset\n",
        "    texts = [\n",
        "        \"This movie is fantastic and I love it!\",\n",
        "        \"I hate this film, it's terrible.\",\n",
        "        \"The acting was superb, a truly great experience.\",\n",
        "        \"What a waste of time, absolutely boring.\",\n",
        "        \"Highly recommend this, a masterpiece.\",\n",
        "        \"Could not finish watching, so bad.\",\n",
        "        \"Amazing storyline, kept me engaged throughout.\",\n",
        "        \"Disappointing and poorly executed.\",\n",
        "        \"Brilliant cinematography and great performances.\",\n",
        "        \"Not worth watching, very dull.\",\n",
        "        \"Exceptional movie, one of the best I've seen.\",\n",
        "        \"Awful, I regret watching this.\",\n",
        "        \"Wonderful experience, loved every scene.\",\n",
        "        \"Boring and predictable plot.\",\n",
        "        \"Outstanding film with excellent direction.\",\n",
        "        \"Terrible waste of money and time.\",\n",
        "        \"Incredible acting and beautiful visuals.\",\n",
        "        \"So bad, couldn't watch till the end.\",\n",
        "        \"Superb entertainment, highly enjoyable.\",\n",
        "        \"Worst movie ever, absolutely horrible.\",\n",
        "        \"Compelling story with emotional depth.\",\n",
        "        \"Poorly written and badly directed.\",\n",
        "        \"Captivating from start to finish.\",\n",
        "        \"Complete disaster, very disappointing.\",\n",
        "        \"Excellent performances all around.\",\n",
        "        \"Waste of time, not recommended.\",\n",
        "        \"Beautiful cinematography and soundtrack.\",\n",
        "        \"Dull and uninspiring movie.\",\n",
        "        \"Must watch, absolutely brilliant.\",\n",
        "        \"Horrible experience, very bad.\",\n",
        "    ]\n",
        "\n",
        "    labels = [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
        "              1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n",
        "\n",
        "    # Split data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
        "    )\n",
        "\n",
        "    print(f\"\\nDataset: {len(texts)} samples\")\n",
        "    print(f\"Training: {len(X_train)} | Testing: {len(X_test)}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # 1. IMPROVED PREPROCESSING\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"1. IMPROVED PREPROCESSING AND FEATURE SELECTION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    preprocessor = AdvancedTextPreprocessor(\n",
        "        remove_urls=True,\n",
        "        remove_special_chars=True,\n",
        "        min_word_length=2,\n",
        "        lowercase=True\n",
        "    )\n",
        "\n",
        "    print(\"\\nCleaning training data...\")\n",
        "    X_train_clean = preprocessor.preprocess_corpus(X_train)\n",
        "    X_test_clean = preprocessor.preprocess_corpus(X_test)\n",
        "\n",
        "    print(\"\\nExample preprocessing:\")\n",
        "    print(f\"Original: '{X_train[0]}'\")\n",
        "    print(f\"Cleaned:  '{X_train_clean[0]}'\")\n",
        "\n",
        "    # Test different vectorizer configurations\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"Comparing different TF-IDF configurations:\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    vectorizer_configs = {\n",
        "        'Basic TF-IDF': {'max_features': None, 'ngram_range': (1, 1)},\n",
        "        'TF-IDF + Bigrams': {'max_features': 1000, 'ngram_range': (1, 2)},\n",
        "        'TF-IDF + min_df=2': {'max_features': 1000, 'ngram_range': (1, 2), 'min_df': 2},\n",
        "        'TF-IDF Reduced (500)': {'max_features': 500, 'ngram_range': (1, 2), 'min_df': 2}\n",
        "    }\n",
        "\n",
        "    for config_name, params in vectorizer_configs.items():\n",
        "        vectorizer = TfidfVectorizer(stop_words='english', **params)\n",
        "        classifier = ImprovedTextClassifier(vectorizer, 'logistic_regression')\n",
        "        classifier.fit(X_train_clean, y_train)\n",
        "\n",
        "        y_pred = classifier.predict(X_test_clean)\n",
        "        metrics = classifier.evaluate(y_test, y_pred)\n",
        "\n",
        "        print(f\"\\n{config_name}:\")\n",
        "        print(f\"  Accuracy: {metrics['accuracy']:.4f} | F1: {metrics['f1_score']:.4f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # 2. ADVANCED EMBEDDING METHODS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"2. ADVANCED EMBEDDING METHODS (Word2Vec)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    print(\"\\nTraining Word2Vec-based classifier...\")\n",
        "    w2v_classifier = SimpleWord2VecClassifier(\n",
        "        embedding_dim=100,\n",
        "        model_type='logistic_regression'\n",
        "    )\n",
        "\n",
        "    w2v_classifier.fit(X_train_clean, y_train)\n",
        "    y_pred_w2v = w2v_classifier.predict(X_test_clean)\n",
        "    metrics_w2v = w2v_classifier.evaluate(y_test, y_pred_w2v)\n",
        "\n",
        "    print(\"\\nWord2Vec Results:\")\n",
        "    print(f\"  Accuracy:  {metrics_w2v['accuracy']:.4f}\")\n",
        "    print(f\"  Precision: {metrics_w2v['precision']:.4f}\")\n",
        "    print(f\"  Recall:    {metrics_w2v['recall']:.4f}\")\n",
        "    print(f\"  F1 Score:  {metrics_w2v['f1_score']:.4f}\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # 3. COMPARING DIFFERENT MODEL ARCHITECTURES\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"3. COMPARING DIFFERENT MODEL ARCHITECTURES\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    results = compare_models(X_train_clean, X_test_clean, y_train, y_test)\n",
        "\n",
        "    # Summary table\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"PERFORMANCE SUMMARY\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Model':<25} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1 Score':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    for model_name, metrics in results.items():\n",
        "        print(f\"{model_name:<25} \"\n",
        "              f\"{metrics['accuracy']:<12.4f} \"\n",
        "              f\"{metrics['precision']:<12.4f} \"\n",
        "              f\"{metrics['recall']:<12.4f} \"\n",
        "              f\"{metrics['f1_score']:<12.4f}\")\n",
        "\n",
        "    # Find best model\n",
        "    best_model = max(results.items(), key=lambda x: x[1]['f1_score'])\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"  Best Model: {best_model[0]} (F1 Score: {best_model[1]['f1_score']:.4f})\")\n",
        "\n",
        "    # ========================================================================\n",
        "    # 4. RECOMMENDATIONS\n",
        "    # ========================================================================\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"RECOMMENDATIONS FOR IMPROVEMENT\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    recommendations = \"\"\"\n",
        "    ✓ Preprocessing Improvements:\n",
        "      • Add spell correction for noisy text\n",
        "      • Use lemmatization instead of simple tokenization\n",
        "      • Experiment with different stop word lists\n",
        "\n",
        "    ✓ Feature Engineering:\n",
        "      • Try character n-grams for capturing style\n",
        "      • Add sentiment lexicon features\n",
        "      • Combine TF-IDF with hand-crafted features\n",
        "\n",
        "    ✓ Advanced Embeddings:\n",
        "      • Use pre-trained Word2Vec (Google News)\n",
        "      • Try GloVe embeddings\n",
        "      • Experiment with FastText for OOV words\n",
        "      • Use contextual embeddings (BERT, if resources allow)\n",
        "\n",
        "    ✓ Model Architecture:\n",
        "      • Try ensemble methods (voting, stacking)\n",
        "      • Experiment with neural networks (LSTM, CNN)\n",
        "      • Use hyperparameter tuning (GridSearch, RandomSearch)\n",
        "\n",
        "    ✓ Data Improvements:\n",
        "      • Collect more training data\n",
        "      • Balance the dataset if imbalanced\n",
        "      • Use data augmentation techniques\n",
        "      • Add cross-validation for robust evaluation\n",
        "    \"\"\"\n",
        "\n",
        "    print(recommendations)\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"TASK 4 COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AVE9MQk3s-N",
        "outputId": "35b8c28c-0895-4a5f-80f3-e332f52cb79e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "TASK 4: EVALUATING AND IMPROVING MODEL PERFORMANCE\n",
            "================================================================================\n",
            "\n",
            "Dataset: 30 samples\n",
            "Training: 24 | Testing: 6\n",
            "\n",
            "================================================================================\n",
            "1. IMPROVED PREPROCESSING AND FEATURE SELECTION\n",
            "================================================================================\n",
            "\n",
            "Cleaning training data...\n",
            "\n",
            "Example preprocessing:\n",
            "Original: 'So bad, couldn't watch till the end.'\n",
            "Cleaned:  'so bad couldnt watch till the end'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Comparing different TF-IDF configurations:\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "Basic TF-IDF:\n",
            "  Accuracy: 0.8333 | F1: 0.8000\n",
            "\n",
            "TF-IDF + Bigrams:\n",
            "  Accuracy: 0.8333 | F1: 0.8000\n",
            "\n",
            "TF-IDF + min_df=2:\n",
            "  Accuracy: 0.5000 | F1: 0.5714\n",
            "\n",
            "TF-IDF Reduced (500):\n",
            "  Accuracy: 0.5000 | F1: 0.5714\n",
            "\n",
            "================================================================================\n",
            "2. ADVANCED EMBEDDING METHODS (Word2Vec)\n",
            "================================================================================\n",
            "\n",
            "Training Word2Vec-based classifier...\n",
            "\n",
            "Word2Vec Results:\n",
            "  Accuracy:  0.6667\n",
            "  Precision: 0.6667\n",
            "  Recall:    0.6667\n",
            "  F1 Score:  0.6667\n",
            "\n",
            "================================================================================\n",
            "3. COMPARING DIFFERENT MODEL ARCHITECTURES\n",
            "================================================================================\n",
            "\n",
            "Training Logistic Regression...\n",
            "  Accuracy: 0.5000\n",
            "  F1 Score: 0.5714\n",
            "\n",
            "Training Naive Bayes...\n",
            "  Accuracy: 0.5000\n",
            "  F1 Score: 0.0000\n",
            "\n",
            "Training Random Forest...\n",
            "  Accuracy: 0.5000\n",
            "  F1 Score: 0.5714\n",
            "\n",
            "Training Gradient Boosting...\n",
            "  Accuracy: 0.5000\n",
            "  F1 Score: 0.5714\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "PERFORMANCE SUMMARY\n",
            "--------------------------------------------------------------------------------\n",
            "Model                     Accuracy     Precision    Recall       F1 Score    \n",
            "--------------------------------------------------------------------------------\n",
            "Logistic Regression       0.5000       0.5000       0.6667       0.5714      \n",
            "Naive Bayes               0.5000       0.0000       0.0000       0.0000      \n",
            "Random Forest             0.5000       0.5000       0.6667       0.5714      \n",
            "Gradient Boosting         0.5000       0.5000       0.6667       0.5714      \n",
            "--------------------------------------------------------------------------------\n",
            "  Best Model: Logistic Regression (F1 Score: 0.5714)\n",
            "\n",
            "================================================================================\n",
            "RECOMMENDATIONS FOR IMPROVEMENT\n",
            "================================================================================\n",
            "\n",
            "    ✓ Preprocessing Improvements:\n",
            "      • Add spell correction for noisy text\n",
            "      • Use lemmatization instead of simple tokenization\n",
            "      • Experiment with different stop word lists\n",
            "    \n",
            "    ✓ Feature Engineering:\n",
            "      • Try character n-grams for capturing style\n",
            "      • Add sentiment lexicon features\n",
            "      • Combine TF-IDF with hand-crafted features\n",
            "    \n",
            "    ✓ Advanced Embeddings:\n",
            "      • Use pre-trained Word2Vec (Google News)\n",
            "      • Try GloVe embeddings\n",
            "      • Experiment with FastText for OOV words\n",
            "      • Use contextual embeddings (BERT, if resources allow)\n",
            "    \n",
            "    ✓ Model Architecture:\n",
            "      • Try ensemble methods (voting, stacking)\n",
            "      • Experiment with neural networks (LSTM, CNN)\n",
            "      • Use hyperparameter tuning (GridSearch, RandomSearch)\n",
            "    \n",
            "    ✓ Data Improvements:\n",
            "      • Collect more training data\n",
            "      • Balance the dataset if imbalanced\n",
            "      • Use data augmentation techniques\n",
            "      • Add cross-validation for robust evaluation\n",
            "    \n",
            "\n",
            "================================================================================\n",
            "TASK 4 COMPLETED SUCCESSFULLY!\n",
            "================================================================================\n"
          ]
        }
      ]
    }
  ]
}